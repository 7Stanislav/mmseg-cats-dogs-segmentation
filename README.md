# Проект: мультиклассовая семантическая сегментация (mmsegmentation)

## Этап 1. Исследовательский анализ (EDA)

### Анализ качества данных

Для первичной проверки датасета был написан скрипт  
`practicum_work/src/data/eda_scan_labels.py`.

Скрипт выполняет **технические проверки**:
- соответствие пар изображение–маска (по имени файла);
- совпадение размеров изображений и масок;
- корректность чтения файлов;
- поиск пустых масок (маска из одного значения);
- сбор уникальных значений классов в масках;
- подсчёт распределения пикселей по классам;
- сохранение оверлеев (img + mask) для ручной проверки.

**Результаты технической проверки:**
- train: label files = 200, pairs checked = 200, bad samples = 0
- val: label files = 120, pairs checked = 120, bad samples = 0

Важно: эти проверки подтверждают только техническую целостность датасета.
Проверка возможных **ошибок разметки** (перепутанные классы, неточная/пропущенная разметка, артефакты по границам) требует отдельного ручного/эвристического анализа и будет выполнена далее.

---

### EDA

**Структура датасета**

train_dataset_for_students/
├── img/
│ ├── train
│ ├── val
│ └── test
└── labels/
├── train
├── val
└── test


По открытым примерам изображения имеют размер 256×256.  
(Точное распределение размеров при необходимости можно зафиксировать отдельной статистикой.)

---

### Классы (по уникальным значениям масок)

По результатам сканирования масок обнаружены значения:
- `[0, 1, 2]`

Значение `255` (ignore index) **не обнаружено**.

Итого: **3 класса (включая фон)**.

---

### Распределение классов по пикселям

**Train subset:**
- value=0: share=0.9086
- value=1: share=0.0498
- value=2: share=0.0416

**Validation subset:**
- value=0: share=0.8926
- value=1: share=0.0655
- value=2: share=0.0419

---

### Артефакты EDA

- JSON-отчёты:
  - `practicum_work/supplementary/viz/eda_report_train.json`
  - `practicum_work/supplementary/viz/eda_report_val.json`
- Оверлеи для ручной проверки разметки:
  - `practicum_work/supplementary/viz/eda_samples/train`
  - `practicum_work/supplementary/viz/eda_samples/val`

### Выявленные проблемы разметки и стратегия чистки

Так как в датасете отсутствует явное описание семантики классов 1/2, была выполнена проверка консистентности классов на основе предобученного классификатора (cat/dog) по исходным изображениям и доминирующего класса в маске.

Скрипт: `practicum_work/src/data/fix_labels_cats_dogs_v1.py`

Результаты проверки (dry-run):

- Инференный маппинг: **cat → 1**, **dog → 2** (в train и val).
- Обнаружены случаи, когда для изображений с собакой доминирует класс 1 (требуется swap 1↔2).
- Обнаружены семплы с крайне малой/почти пустой маской в train: `tiny_or_empty_mask = 4` — кандидаты на удаление/доразметку.

Стратегия чистки (clean_v1):
1) Зафиксировать глобальную семантику: **1 = cat, 2 = dog**.
2) Для семплов, где по уверенной классификации виден swap классов, выполнить обмен меток **1↔2** в маске.
3) Семплы с практически пустой маской исключить из обучающего поднабора (или отправить на ручную доразметку).

Исходный датасет не модифицируется. Очищенная версия сохраняется отдельно:
`clean_v1/`

### Результат чистки разметки

После автоматической проверки и исправления семантики классов был сформирован очищенный датасет `clean_v1`.

Итоги проверки на `clean_v1`:
- Семантика классов согласована: **1 = cat, 2 = dog**.
- Перепутанные классы (1↔2) устранены.
- Семплы с пустой/минимальной маской удалены из train (4 изображения).
- Повторная проверка консистентности показала отсутствие семантических конфликтов в train и val.

Очищенная версия датасета:
`clean_v1/`

Исходный датасет сохранён без изменений.

## Этап 2. Формирование первичных гипотез

Данные: очищенная версия датасета `clean_v1/` (3 класса: background / cat / dog).

Цель этапа: получить стартовые бейзлайны, зафиксировать конфиги экспериментов и провести первичный анализ качества.

### Стартовая гипотеза 1 (hyp1_segformer_b0)

**Описание гипотезы**  
Модель: SegFormer-B0 (EncoderDecoder + SegFormerHead).  
Лосс: CrossEntropyLoss + DiceLoss.  
Логика выбора: лёгкая современная архитектура, хорошая стартовая точка для мультиклассовой сегментации на небольшом датасете.

**Результаты обучения**  
Конфиг: `configs/hyp1_segformer_b0.py`  
Логи/артефакты: `work_dirs/hyp1_segformer_b0/`  
mDice (val): 0.5736 на итерации 1000 (лучшее значение по логам)
ClearML: https://app.clear.ml/projects/fa54446dd169484ba2dba6a7ad20e512/experiments/6dc71a25c3364a869f93eab0d2cf8e77/output/execution

**Анализ качества**  
Сегментация фона стабильная, качество по классам cat/dog ограничено из-за дисбаланса классов (фон доминирует). Требуются эксперименты с балансировкой лосса и/или усилением обучающего сигнала по редким классам.

---

### Стартовая гипотеза 2 (hyp2_segformer_b0_wce)

**Описание гипотезы**  
Модель: SegFormer-B0.  
Изменение: добавлены веса классов в CE (class-weighted CE) для компенсации сильного дисбаланса по пикселям.

**Результаты обучения**  
Конфиг: `configs/hyp2_segformer_b0_wce.py`  
Логи/артефакты: `work_dirs/hyp2_segformer_b0_wce/`  
mDice (val): 0.5908 на итерации 2000 (best_mDice_iter_2000.pth)
ClearML: https://app.clear.ml/projects/fa54446dd169484ba2dba6a7ad20e512/experiments/cefee184c667409c843da824e4c6636c/output/execution

**Анализ качества**  
Улучшение качества по редким классам по сравнению с hyp1, но модель всё ещё ошибается на границах и в сложных сценах.

---

### Стартовая гипотеза 3 (hyp3_segformer_b0_wce_soft)

**Описание гипотезы**  
Модель: SegFormer-B0.  
Изменение: class-weighted CE + более “мягкая” схема весов (или сглаживание/нормировка весов), чтобы не перегнуть обучение и не просадить фон.

**Результаты обучения**  
Конфиг: `configs/hyp3_segformer_b0_wce_soft.py`  
Логи/артефакты: `work_dirs/hyp3_segformer_b0_wce_soft/`  
mDice (val) = 0.5991 (iter 3000, лучший чекпойнт best_mDice_iter_3000.pth)
ClearML: https://app.clear.ml/projects/fa54446dd169484ba2dba6a7ad20e512/experiments/3f6828002877425b838969ee33f35c86/output/execution

**Анализ качества**  
Компромисс между качеством по фону и объектам; всё ещё заметны ошибки на тонких деталях и при окклюзии.


## Этап 3. Эксперименты по улучшению качества

После стартовых гипотез (SegFormer-B0) основной проблемой оставался дисбаланс классов и слабая сегментация объектов (cat/dog) на фоне доминирующего background.

---

### Эксперимент 1 — SegFormer-B0 + “мягкие” веса классов (soft weighted CE)

**Описание эксперимента**

Попробовал модификацию взвешенной CrossEntropy: вместо “жёстких” весов использованы более мягкие коэффициенты (soft-веса), чтобы:
- не “перекачать” редкие классы
- сохранить стабильность обучения
- улучшить cat/dog без деградации фона

Конфиг:
`configs/hyp3_segformer_b0_wce_soft.py`

**Результаты обучения**

mDice (val) = 0.5991 (iter 3000)

**Анализ качества**

Существенного прироста не дало: ограничения архитектуры SegFormer-B0 для этого датасета оказались критичными.  
Вывод: нужно менять архитектуру (более мощный backbone / другой тип модели).

---

### Эксперимент 2 — DeepLabV3+ (ResNet-50) + балансировка через лоссы/настройки обучения

**Описание эксперимента**

Проверил более сильную CNN-архитектуру **DeepLabV3+ с ResNet-50**, которая часто лучше работает на задачах с объектами среднего размера и выраженным фоном.

Цель:
- получить скачок качества по cat/dog
- улучшить границы объектов
- стабильно держать фон

Конфиг:
`configs/hyp4_deeplabv3p_r50.py`
ClearML: https://app.clear.ml/projects/fa54446dd169484ba2dba6a7ad20e512/experiments/0b578e4f2c4e4eb5aa97c9cb806b4d5c

**Результаты обучения**

На тестовом сплите получено:
- **mDice (test) = 0.8978**
- per-class (test):
  - background Dice ≈ 98.78
  - cat Dice ≈ 87.53
  - dog Dice ≈ 83.02

**Анализ качества**

Эксперимент дал существенный прирост качества и уверенно превысил целевую метрику проекта (mDice > 0.75).  
Для анализа ошибок/успехов дополнительно сохранены примеры лучших/худших предсказаний на тесте:
`practicum_work/supplementary/viz/qual_test_top_bottom/`

## Этап 4. Заключение и выбор лучшего эксперимента

### Лучший эксперимент

Лучшим оказался эксперимент с архитектурой **DeepLabV3+ (ResNet-50)**  
Конфиг: `configs/hyp4_deeplabv3p_r50.py`
ClearML: https://app.clear.ml/projects/fa54446dd169484ba2dba6a7ad20e512/experiments/0b578e4f2c4e4eb5aa97c9cb806b4d5c

Причины выбора:

- Существенный прирост качества по сравнению с SegFormer-B0
- Улучшение сегментации объектов cat и dog
- Стабильная работа на фоне доминирующего background
- Уверенное превышение целевой метрики проекта

**mDice (test) = 0.8978**

Per-class (test):

- background Dice ≈ 98.78  
- cat Dice ≈ 87.53  
- dog Dice ≈ 83.02  

Модель демонстрирует сбалансированное качество по всем классам и не переобучается на фон.

---

### Примеры корректных предсказаний (тестовый датасет)

Примеры сохранены в:

`practicum_work/supplementary/viz/qual_test_top_bottom/best/`

(3–5 примеров изображений с корректной сегментацией)

---

### Примеры ошибок (тестовый датасет)

Примеры сохранены в:

`practicum_work/supplementary/viz/qual_test_top_bottom/worst/`

(3–5 примеров изображений, где модель допускает ошибки)

Типичные ошибки:

- частичная потеря границ объекта  
- путаница cat/dog в сложных сценах  
- недосегментация мелких деталей  

---

### Возможности для улучшения

1. Использование более мощного backbone (ResNet-101 / ConvNeXt / Swin).
2. Применение более сложных аугментаций (color jitter, scale jitter, random crop с фокусом на объекты).
3. Использование комбинированного лосса (Dice + Focal).
4. Доразметка или дополнительная чистка проблемных масок.
5. K-fold cross-validation для более устойчивой оценки качества.

---

Проект успешно достиг целевой метрики mDice > 0.75.

## Этап 5. Документация кода

Весь вспомогательный код расположен в сабмодуле `practicum_work`.

Структура:

practicum_work
├── src
│ ├── data
│ │ ├── eda_scan_labels.py
│ │ ├── fix_labels_cats_dogs_v1.py
│ ├── analysis
│ │ ├── save_best_worst_predictions.py
│
├── supplementary
│ ├── viz
│ │ ├── eda_report_train.json
│ │ ├── eda_report_val.json
│ │ ├── eda_report_test.json
│ │ ├── label_fix_report_train.json
│ │ ├── label_fix_report_val.json
│ │ ├── qual_test_top_bottom


---

### Описание скриптов

#### `eda_scan_labels.py`

- Проверяет корректность масок
- Подсчитывает распределение классов
- Выявляет пустые и поврежденные разметки
- Генерирует JSON-отчёт для анализа

Использовался на этапе EDA.

---

#### `fix_labels_cats_dogs_v1.py`

- Исправляет обнаруженные проблемы в масках
- Нормализует значения классов
- Удаляет или корректирует ошибочные разметки
- Формирует отчёт об исправлениях

Использовался при чистке датасета.

---

#### `save_best_worst_predictions.py`

- Загружает обученную модель
- Считает Dice для каждого изображения
- Сохраняет:
  - лучшие предсказания
  - худшие предсказания
- Используется для анализа качества и подготовки иллюстраций в отчёт

---

### Конфигурации экспериментов

Все гипотезы находятся в:

configs/
├── hyp1_segformer_b0.py
├── hyp2_segformer_b0_wce.py
├── hyp3_segformer_b0_wce_soft.py
├── hyp4_deeplabv3p_r50.py


Каждый конфиг фиксирует:
- архитектуру
- лосс-функцию
- аугментации
- параметры обучения

---

Проект реализован на базе mmsegmentation с добавленным сабмодулем practicum_work, содержащим весь вспомогательный код и артефакты.

Проект полностью воспроизводим:  
конфиги, скрипты анализа и структура датасета зафиксированы в репозитории.
